\section{Implications}

As more technology companies' data practices come to light, their users and
employees alike are becoming increasingly uncomfortable with common practice.
The data economy has created a demand for granular user data, which has become
increasingly influential in how companies become profitable. The implications
of this economy has raised ethical and moral concerns.


% How categorizing data dehumanizes and reinforces bias and racism
\para{Dehumanizing}
Francis Grund wrote of the deeply personal nature of the 20\ts{th} century
American credit system and considered this its defining feature. Critics of the
modern system point out the dehumanizing nature the credit system and many
others that rely on big data. In order for predictive models to make
classifications on or inferences about statistical populations, non-numerical
data representing a person needs to be transformed. For example, whether you're marital status is
single, divorced, or married needs to be represented as a numerical value. This
is the case for all non-numerical data. At what cost are we transforming an individual's data to fit the
models that shape the lives of many?

The categorization of data began with the \mca, where data collectors used
short hand to describe features of the data. They created rating systems
similar to the mapping of academic performance to letter
grades~\cite{lauer2017creditworthy}. In the 1960-70's, credit bureaus were faced
with the challenge of identifying individuals and called for a universal
numbering system. The obvious choice at this time was the Social Security
Number. The financial industry had already began using it as an identifier for
individuals and faced no legal challenges for non-governmetnal use. With the
use of this number as an identifier, the crediting agencies reduced a person to
a numerical value.

% Figure for sql join on ssn
\begin{center}
\begin{lstlisting}[language=SQL, basicstyle=\sffamily]
		SELECT ssn, name, address, creditScore
				FROM master
				WHERE ssn=@target
\end{lstlisting}
\end{center}

% Not sure if this belongs here.
% What am I saying here?
Proponents of these new systems feel that they are realizing American democracy
and leveling the playing field, while others consider it rise in
totalitarianism. The selling point of maintaining these data sets and
automated systems is that products become cheaper and can be used more widely.
Increased availability and decreased cost means that more socio-economic
classes are able to use these products. This was indeed the argument in the
early 20\ts{th} century credit system. Nevertheless, these systems depend on
rational groups to maintain these systems and data sets. The cost of a system
like this is privacy. As the demarcation between digital and physical spaces
becomes increasingly less apparent, the gaze of the surviellance entities is
more profound, producing a reality of constant surviellance. Americans did not
realize how much they were giving up until the late 1960's during congressional
hearings~\cite{lauer2017creditworthy}.

% Interesting note on pg 183 of Lauer

\para{Companies Respond}
The common response by technology companies is the "trust us" model. Under this
model, technology companies invoke self-governance as the response to ever
growing concern that user data is being unethically and immorally exploited.
This particular model may disrupt and obstruct governmental regulation. Ethical
codes of conduct will deflect concerns, ultimately avoiding a reckoning~\cite{whittaker2018ai}

Technology companies have responded in various ways. Google's CEO Sundar Pichai
published \textit{AI at Google: our principles} in June of 2018. There, he
outlines how Google's AI products will not reinforce bias or cause harm, and
will be accountable, privacy sensitive, and benefit society. What is not
outlined is what body will oversee the implementation of these principles in
practice. Google has already struggled with composing a body that would oversee
this, as their newly formed Ethics Board was absolved after 8 days of existence.

\para{Engineers Respond}

