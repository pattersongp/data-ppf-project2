\section{Implications}

As more technology companies' data practices come to light, their users and
employees alike are becoming increasingly uncomfortable with common practice.
The data economy has created a demand for granular user data, which has become
increasingly influential in how companies become profitable. The implications
of this economy has raised ethical and moral concerns.


% How categorizing data dehumanizes and reinforces bias and racism
\para{Dehumanizing}
Francis Grund wrote of the deeply personal nature of the 20\ts{th} century American
credit system and considered this its defining feature. Critics of the modern
system point out the dehumanizing nature the credit system and many others that rely on
big data. In order for predictive models to make classifications on or inferences
about statistical populations, non-numerical data needs to be transformed. For example,
whether you're marital status is single, divorced, or married needs to be represented
as a numerical value. This is the case for all non-numerical data. At what cost are
we fitting data to the models that shape the lives of many?

% Not sure if this belongs here.
% What am I saying here?
Proponents of these new systems feel that they are realizing American democracy
and leveling the playing field, while others consider it rise in
totalitarianism. The selling point of maintaining these data sets and
automated systems is that products become cheaper and can be used more widely.
Increased availability and decreased cost means that more socio-economic
classes are able to use these products. This was indeed the argument in the
early 20\ts{th} century credit system. Nevertheless, these systems depend on
rational groups to maintain these systems and data sets. The cost of a system
like this is privacy. As the demarcation between digital and physical spaces
becomes increasingly less apparent, the gaze of the surviellance entities is
more profound, producing a reality of constant surviellance. Americans did not
realize how much they were giving up until the late 1960's during congressional
hearings~\cite{lauer2017creditworthy}.

\para{Companies Respond}
The common response by technology companies is the "trust us" model. Under this
model, technology companies invoke self-governance as the response to ever
growing concern that user data is being unethically and immorally exploited.
This particular model may disrupt and obstruct governmental regulation. Ethical
codes of conduct will deflect concerns, ultimately avoiding a reckoning~\cite{whittaker2018ai}

Technology companies have responded in various ways. Google's CEO Sundar Pichai
published \textit{AI at Google: our principles} in June of 2018. There, he
outlines how Google's AI products will not reinforce bias or cause harm, and
will be accountable, privacy sensitive, and benefit society. What is not
outlined is what body will oversee the implementation of these principles in
practice. Google has already struggled with composing a body that would oversee
this, as their newly formed Ethics Board was absolved after 8 days of existence.

\para{Engineers Respond}

